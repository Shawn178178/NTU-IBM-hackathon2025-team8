{
 "cells": [
  {
   "cell_type": "code",
   "id": "a6ce99ce",
   "metadata": {},
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import rustworkx as rx\n",
    "from rustworkx.visualization import mpl_draw as draw_graph\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from collections import defaultdict\n",
    "from typing import Sequence\n",
    " \n",
    " \n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit.circuit.library import QAOAAnsatz\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    " \n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "from qiskit_ibm_runtime import Session, EstimatorV2 as Estimator\n",
    "from qiskit_ibm_runtime import SamplerV2 as Sampler\n",
    "\n",
    "global_print_counter = 0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a98e5c09",
   "metadata": {},
   "source": [
    "### else ###\n",
    "\n",
    "from qiskit.providers.fake_provider import GenericBackendV2\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit.visualization import plot_histogram\n",
    "from rustworkx.visualization import mpl_draw\n",
    "import math"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6d1b8c08",
   "metadata": {},
   "source": [
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "service = QiskitRuntimeService()\n",
    "real_backend = service.backend('ibm_strasbourg')\n",
    "\n",
    "\n",
    "simulator_backend = AerSimulator()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5de1501a",
   "metadata": {},
   "source": [
    "def build_max_cut_paulis(graph: rx.PyGraph) -> list[tuple[str, float]]:\n",
    "    \"\"\"Convert the graph to Pauli list.\n",
    " \n",
    "    This function does the inverse of `build_max_cut_graph`\n",
    "    \"\"\"\n",
    "    pauli_list = []\n",
    "    for edge in list(graph.edge_list()):\n",
    "        weight = graph.get_edge_data(edge[0], edge[1])\n",
    "        pauli_list.append((\"ZZ\", [edge[0], edge[1]], weight))\n",
    "    return pauli_list\n",
    " \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "74d465f1",
   "metadata": {},
   "source": [
    "def cost_func_estimator(params, ansatz, hamiltonian, estimator):\n",
    "    # transform the observable defined on virtual qubits to\n",
    "    # an observable defined on all physical qubits\n",
    "    isa_hamiltonian = hamiltonian.apply_layout(ansatz.layout)\n",
    " \n",
    "    pub = (ansatz, isa_hamiltonian, params)\n",
    "    job = estimator.run([pub])\n",
    "    global global_print_counter  \n",
    "    global_print_counter += 1\n",
    " \n",
    "    results = job.result()[0]\n",
    "    cost = results.data.evs\n",
    " \n",
    "    return cost"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "81d74d72",
   "metadata": {},
   "source": [
    "\n",
    "def optimization(back_end, init_params, candidate_circuit, cost_hamiltonian):\n",
    "    with Session(backend=back_end) as session:\n",
    "        # If using qiskit-ibm-runtime<0.24.0, change `mode=` to `session=`\n",
    "        estimator = Estimator(mode=session)\n",
    "        estimator.options.default_shots = 1000\n",
    "    \n",
    "        # Set simple error suppression/mitigation options\n",
    "        estimator.options.dynamical_decoupling.enable = True\n",
    "        estimator.options.dynamical_decoupling.sequence_type = \"XY4\"\n",
    "        estimator.options.twirling.enable_gates = True\n",
    "        estimator.options.twirling.num_randomizations = \"auto\"\n",
    "    \n",
    "        result = minimize(\n",
    "            cost_func_estimator,\n",
    "            init_params,\n",
    "            args=(candidate_circuit, cost_hamiltonian, estimator),\n",
    "            method=\"COBYLA\",\n",
    "            options={\"maxiter\": 200, \"rhobeg\": 1, \"catol\": 1e-3, \"tol\": 0.0001},\n",
    "        )\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "28a6ac3f",
   "metadata": {},
   "source": [
    "# If using qiskit-ibm-runtime<0.24.0, change `mode=` to `backend=`\n",
    "def exam_parameters(session, optimized_circuit):\n",
    "    sampler = Sampler(mode=session)\n",
    "    sampler.options.default_shots = 10000\n",
    "    \n",
    "    # Set simple error suppression/mitigation options\n",
    "    sampler.options.dynamical_decoupling.enable = True\n",
    "    sampler.options.dynamical_decoupling.sequence_type = \"XY4\"\n",
    "    sampler.options.twirling.enable_gates = True\n",
    "    sampler.options.twirling.num_randomizations = \"auto\"\n",
    "    \n",
    "    pub = (optimized_circuit,)\n",
    "    job = sampler.run([pub], shots=int(1e4))\n",
    "    global global_print_counter \n",
    "    global_print_counter += 1\n",
    "    counts_int = job.result()[0].data.meas.get_int_counts()\n",
    "    counts_bin = job.result()[0].data.meas.get_counts()\n",
    "    shots = sum(counts_int.values())\n",
    "    final_distribution_int = {key: val / shots for key, val in counts_int.items()}\n",
    "    final_distribution_bin = {key: val / shots for key, val in counts_bin.items()}\n",
    "    return (counts_bin, final_distribution_bin, final_distribution_int)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "49d91068",
   "metadata": {},
   "source": [
    "# If using qiskit-ibm-runtime<0.24.0, change `mode=` to `backend=`\n",
    "def exam_parameters_qopt(session, optimized_circuit, shots):\n",
    "    sampler = Sampler(mode=session)\n",
    "    sampler.options.default_shots = shots\n",
    "    \n",
    "    # Set simple error suppression/mitigation options\n",
    "    sampler.options.dynamical_decoupling.enable = True\n",
    "    sampler.options.dynamical_decoupling.sequence_type = \"XY4\"\n",
    "    sampler.options.twirling.enable_gates = True\n",
    "    sampler.options.twirling.num_randomizations = \"auto\"\n",
    "    \n",
    "    pub = (optimized_circuit,)\n",
    "    job = sampler.run([pub], shots=int(shots))\n",
    "    global global_print_counter \n",
    "    global_print_counter += 1\n",
    "    job_id = job.job_id()\n",
    "    print(job_id)\n",
    "    counts_int = job.result()[0].data.meas.get_int_counts()\n",
    "    counts_bin = job.result()[0].data.meas.get_counts()\n",
    "    shots = sum(counts_int.values())\n",
    "    final_distribution_int = {key: val / shots for key, val in counts_int.items()}\n",
    "    final_distribution_bin = {key: val / shots for key, val in counts_bin.items()}\n",
    "    return (counts_bin, final_distribution_bin, final_distribution_int)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2a0312a9",
   "metadata": {},
   "source": [
    "# auxiliary functions to sample most likely bitstring\n",
    "def find_result_bitstring(final_distribution_int):\n",
    "\n",
    "    def to_bitstring(integer, num_bits):\n",
    "        result = np.binary_repr(integer, width=num_bits)\n",
    "        return [int(digit) for digit in result]\n",
    "    \n",
    "    \n",
    "    keys = list(final_distribution_int.keys())\n",
    "    values = list(final_distribution_int.values())\n",
    "    most_likely = keys[np.argmax(np.abs(values))]\n",
    "    most_likely_bitstring = to_bitstring(most_likely, len(graph))\n",
    "    return most_likely_bitstring\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4ca41e73",
   "metadata": {},
   "source": [
    "def plot_graph_purple(final_distribution_bin, top_n):\n",
    "    matplotlib.rcParams.update({\"font.size\": 10})\n",
    "    final_bits = final_distribution_bin\n",
    "    values = np.abs(list(final_bits.values()))\n",
    "    top_4_values = sorted(values, reverse=True)[:top_n]\n",
    "    positions = []\n",
    "    for value in top_4_values:\n",
    "        positions.append(np.where(values == value)[0])\n",
    "    fig = plt.figure(figsize=(20, 6))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(\"Result Distribution\")\n",
    "    plt.xlabel(\"Bitstrings (reversed)\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    ax.bar(list(final_bits.keys()), list(final_bits.values()), color=\"tab:grey\")\n",
    "    for p in positions:\n",
    "        idx = int(np.array(p).item()) ###\n",
    "        ax.get_children()[int(p)].set_color(\"tab:purple\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d3f564ba",
   "metadata": {},
   "source": [
    "# auxiliary function to plot graphs\n",
    "def plot_result(G, x):\n",
    "    colors = [\"tab:grey\" if i == 0 else \"tab:purple\" for i in x]\n",
    "    pos, _default_axes = rx.spring_layout(G), plt.axes(frameon=True)\n",
    "    rx.visualization.mpl_draw(\n",
    "        G, node_color=colors, node_size=100, alpha=0.8, pos=pos\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4d458f29",
   "metadata": {},
   "source": [
    "def evaluate_sample(x: Sequence[int], graph: rx.PyGraph) -> float:\n",
    "    assert len(x) == len(\n",
    "        list(graph.nodes())\n",
    "    ), \"The length of x must coincide with the number of nodes in the graph.\"\n",
    "    return sum(\n",
    "        w*(x[u] * (1 - x[v]) + x[v] * (1 - x[u]))\n",
    "        for u, v, w in list(graph.weighted_edge_list())\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "52462535",
   "metadata": {},
   "source": [
    "def solutions_to_coordinates(solutions):\n",
    "    arr_d = []\n",
    "    for i in solutions:\n",
    "        lst = [int(c) for c in i]\n",
    "        cut_value_x = evaluate_sample(lst, graph1)\n",
    "        cut_value_y = evaluate_sample(lst, graph2)\n",
    "        arr_d.append((cut_value_x, cut_value_y))\n",
    "    return arr_d\n",
    "\n",
    "def draw_hv(points, area):\n",
    "    \n",
    "    def find_undominated(points):\n",
    "        undominated = []\n",
    "        for p in points:\n",
    "            dominated = False\n",
    "            for q in points:\n",
    "                if q[0] >= p[0] and q[1] >= p[1] and q != p:\n",
    "                    dominated = True\n",
    "                    break\n",
    "            if not dominated:\n",
    "                undominated.append(p)\n",
    "        return undominated\n",
    "\n",
    "    undom_points = find_undominated(points)\n",
    "\n",
    "    # 畫圖\n",
    "    x_all, y_all = zip(*points)\n",
    "    x_undom, y_undom = zip(*undom_points)\n",
    "\n",
    "    plt.title(f'Pareto Front for nodes:{n}, hv:{area:.3f}')\n",
    "    plt.scatter(x_all, y_all, color='lightgray', label='Dominated points')\n",
    "    plt.scatter(x_undom, y_undom, color='red', label='Undominated points')\n",
    "    plt.xlabel('cuts*weights of graph1')\n",
    "    plt.ylabel('cuts*weights of graph2')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "65eb161d",
   "metadata": {},
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "# added in the morning\n",
    "def hv_2d(points):\n",
    "    points = np.array(points)\n",
    "    # Add the origin point\n",
    "    points = np.vstack([points, [0, 0]])\n",
    "    hull = ConvexHull(points)\n",
    "    hull_points = points[hull.vertices]\n",
    "\n",
    "    x = hull_points[:, 0]\n",
    "    y = hull_points[:, 1]\n",
    "    area = 0.5 * abs(np.dot(x, np.roll(y, -1)) - np.dot(y, np.roll(x, -1)))\n",
    "    return area"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "area = hv_2d([(0,2), (2,2), (2,0)])\n",
    "print(area)"
   ],
   "id": "4a9ed634c132bdbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9805ad27",
   "metadata": {},
   "source": [
    "# Scale it up #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28689f35",
   "metadata": {},
   "source": [
    "## preprocessing ##"
   ]
  },
  {
   "cell_type": "code",
   "id": "ee52f37f",
   "metadata": {},
   "source": [
    "### parameters ###\n",
    "n = 5\n",
    "initial_gamma = np.pi\n",
    "initial_beta = np.pi / 2\n",
    "reps = 4\n",
    "p1, p2 = 0.5, 0.5\n",
    "num_dots = 10 ### the amounts of Hc ###\n",
    "\n",
    "\n",
    "graph = rx.PyGraph()\n",
    "graph.add_nodes_from(np.arange(0, n, 1))\n",
    "edge_list = [\n",
    "    (0, 1, 1),\n",
    "    (1, 2, 1),\n",
    "    (2, 3, 1),\n",
    "    (3, 4, 1),\n",
    "]\n",
    "graph.add_edges_from(edge_list)\n",
    "draw_graph(graph, node_size=600, with_labels=True)\n",
    "max_cut_paulis = build_max_cut_paulis(graph)\n",
    "cost_hamiltonian = SparsePauliOp.from_sparse_list(max_cut_paulis, n)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "18691096",
   "metadata": {},
   "source": [
    "circuit = QAOAAnsatz(cost_operator=cost_hamiltonian, reps=reps)\n",
    "circuit.measure_all()\n",
    "pm = generate_preset_pass_manager(optimization_level=3, backend=real_backend)\n",
    "candidate_circuit = pm.run(circuit)\n",
    "init_params = [initial_beta]*reps + [initial_gamma]*reps\n",
    "result = optimization(simulator_backend, init_params, candidate_circuit, cost_hamiltonian)\n",
    "print(result)\n",
    "optimized_params = result.x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a0ee6ed0",
   "metadata": {},
   "source": [
    "## generating graph ##"
   ]
  },
  {
   "cell_type": "code",
   "id": "f680f1e9",
   "metadata": {},
   "source": [
    "n = 18 # number of nodes\n",
    "generic_backend_ext = GenericBackendV2(n, seed=42)\n",
    "graph_structure = list(generic_backend_ext.coupling_map)[::2]\n",
    "num_edges = len(graph_structure)\n",
    "graph_weight1 = np.random.uniform(1, 10, size=num_edges)\n",
    "graph_weight2 = (np.max(graph_weight1) + np.min(graph_weight1)) - graph_weight1 \\\n",
    "                   + np.random.uniform(-4, 4, size=num_edges)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7e18767f",
   "metadata": {},
   "source": [
    "def construct_graph(graph_structure, graph_weight, n):\n",
    "    graph = rx.PyGraph()\n",
    "    graph.add_nodes_from(np.arange(0, n, 1))\n",
    "\n",
    "    edge_list = []\n",
    "    for (node, weight) in zip(graph_structure, graph_weight):\n",
    "        edge_list.append((node[0], node[1], weight))\n",
    "\n",
    "    graph.add_edges_from(edge_list)\n",
    "    \n",
    "    return graph\n",
    "graph1 = construct_graph(graph_structure, graph_weight1, n)\n",
    "graph2 = construct_graph(graph_structure, graph_weight2, n)\n",
    "graph_weight = p1*graph_weight1+ p2*graph_weight2\n",
    "graph = construct_graph(graph_structure, graph_weight, n)\n",
    "\n",
    "# draw_graph(graph, node_size=600, with_labels=True)\n",
    "mpl_draw(graph, with_labels=True, edge_labels=str, node_color=\"#1192E8\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2872848b",
   "metadata": {},
   "source": [
    "# execution #"
   ]
  },
  {
   "cell_type": "code",
   "id": "dffd8ae0",
   "metadata": {},
   "source": [
    "def run_two_hamiltonian(session, graph_structure, graph_weight1, graph_weight2, reps, num_dots, optimized_params):\n",
    "    ### build graph ###\n",
    "    \n",
    "    graph1 = construct_graph(graph_structure, graph_weight1, n)\n",
    "    graph2 = construct_graph(graph_structure, graph_weight2, n)\n",
    "    solution_list_total = []\n",
    "    ### interation start ! ###\n",
    "    for i in range(num_dots):\n",
    "        p1, p2 = i/num_dots, 1-i/num_dots\n",
    "        graph_weight = p1*graph_weight1+ p2*graph_weight2\n",
    "        graph = construct_graph(graph_structure, graph_weight, n)\n",
    "        max_cut_paulis = build_max_cut_paulis(graph)\n",
    "        cost_hamiltonian = SparsePauliOp.from_sparse_list(max_cut_paulis, n)\n",
    "\n",
    "        ### optimized_circuit ###\n",
    "        circuit = QAOAAnsatz(cost_operator=cost_hamiltonian, reps=reps)\n",
    "        circuit.measure_all()\n",
    "        pm = generate_preset_pass_manager(optimization_level=3, backend=real_backend)\n",
    "        candidate_circuit = pm.run(circuit)\n",
    "        model_circuit = candidate_circuit.assign_parameters(optimized_params)\n",
    "\n",
    "        ### sample ###\n",
    "        (counts_bin, final_distribution_bin, final_distribution_int) = exam_parameters_qopt(session, model_circuit, 1024)\n",
    "        \n",
    "        solution_list = list(counts_bin.keys())\n",
    "        solution_list_total.extend(solution_list)\n",
    "\n",
    "\n",
    "    arr_d = solutions_to_coordinates(solution_list_total)\n",
    "    area = hv_2d(arr_d) #added in the new morning \n",
    "    \n",
    "    ### show result ###\n",
    "    draw_hv(arr_d, area)\n",
    "    \n",
    "\n",
    "with Session(backend=real_backend) as session:\n",
    "    run_two_hamiltonian(session, graph_structure, graph_weight1, graph_weight2, reps, num_dots, optimized_params)\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv30",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
